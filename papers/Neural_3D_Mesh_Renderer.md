[**Neural 3D Mesh Renderer**](https://github.com/Big-Brother-Pikachu/Paper-Contributions-Analysis#11-neural-3d-mesh-renderer)

# Contributions in my words

1. They proposed neural 3D mesh renderer to differentially generate images from 3D mesh. They proposed an approximate gradient for rasterization that enables the integration of rendering into neural networks.
2. With this renderer, they proposed a simple method that performs well on single-image 3D mesh reconstruction task.
3. They showed that it is possible to perform gradient-based 3D mesh editing operations with this renderer.

# Contributions they claim

1. We propose an approximate gradient for rendering of a mesh, which enables the integration of rendering into neural networks.
2. We perform 3D mesh reconstruction from single images without 3D supervision and demonstrate our system's advantages over the voxel-based approach.
3. We perform gradient-based 3D mesh editing operations, such as 2D-to-3D style transfer and 3D DeepDream, with 2D supervision for the first time.
4. We will release the code for Neural Renderer.

# Contributions in my words modified

1. They proposed neural 3D mesh renderer to differentially generate images from 3D mesh. They proposed an approximate gradient for rasterization that enables the integration of rendering into neural networks.
2. With this renderer, they proposed a simple method that **outperforms the existing voxel-based approach** on the single-image 3D mesh reconstruction task **without 3D supervision**.
3. With this renderer, they showed that it is possible to perform gradient-based 3D mesh editing operations **for the first time**.